{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries\n"
      ],
      "metadata": {
        "id": "8o0Zc3O6zu0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "t4BgpVsSzsnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d51c5a-ed97-47ae-a21d-036ee3ea151f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for text preprocessing\n"
      ],
      "metadata": {
        "id": "GzQSEvgOz68v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    text = [word for word in text if not word in set(stopwords.words('english'))]\n",
        "    text = ' '.join(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "hAEW8RjOz-jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pre-trained model\n"
      ],
      "metadata": {
        "id": "qQ7XT2xC0CDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "kJs4SaVQ0Dyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Function for sentiment analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "_LhFOUaa0Jig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(input_text):\n",
        "    # Preprocess the input text\n",
        "    input_text = preprocess_text(input_text)\n",
        "\n",
        "    # Vectorize the input text using the same vectorizer as during training\n",
        "    input_vectorized = vectorizer.transform([input_text])\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = loaded_model.predict(input_vectorized)\n",
        "\n",
        "    # Display the result\n",
        "    if prediction[0] == 0:\n",
        "        return 'Negative Tweet'\n",
        "    else:\n",
        "        return 'Positive Tweet'"
      ],
      "metadata": {
        "id": "TnMIzK0Q0MDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the vectorizer used during training\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BqcGBTSM0PgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = pickle.load(open('vectorizer.sav', 'rb'))"
      ],
      "metadata": {
        "id": "sJPdrm5U0QR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input Tweet"
      ],
      "metadata": {
        "id": "Z9vClhkQ0Umw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter a tweet: \") #Input tweet -- ARE YOU MAD ?\n",
        "result = predict_sentiment(user_input)\n",
        "print(\"Prediction:\", result)\n"
      ],
      "metadata": {
        "id": "npRfnndD0V1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4640626-f497-4a25-d0d9-4ad59041831d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a tweet: \"Just had the worst flight experience of my life. Delays, cancellations, and lost luggage – you name it, it happened. Absolutely disgusted with the lack of professionalism from the airline. #TravelNightmare #NeverAgain\"\n",
            "Prediction: Negative Tweet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Positive:\n",
        "\"Just had the most amazing meal at this new restaurant in town! The food was delicious, the service was impeccable, and the ambiance was perfect. Highly recommend checking it out! #Foodie #NewFavoriteSpot\"\n",
        "\n",
        "\"Visited the local orphanage today and spent time playing with the kids. Their laughter and joy are infectious! It's moments like these that remind me of the importance of spreading love and kindness. #SpreadJoy #Community\"\n",
        "\n",
        "\"Received a surprise visit from an old friend today! It was so heartwarming to catch up and reminisce about old times. Grateful for friendships that stand the test of time. #FriendsForever #Blessed\"\n",
        "\n",
        "\"Just finished reading a book that completely captivated me from start to finish. There's something magical about getting lost in a good story. Can't wait to dive into my next read! #Bookworm #EscapeThroughReading\"\n",
        "\n",
        "#Negative:\n",
        "\n",
        "\"It is very unfortunate for any exam paper to be leaked. This breaks the morale of the students and they lose faith in the government. #EducationSystemFail #CheatingScandal\"\n",
        "\n",
        "\n",
        "\"The customer service at this store is absolutely appalling. Waited in line for over an hour only to be met with rude and unhelpful staff. Never shopping here again! #CustomerServiceFail #WorstShoppingExperience\"\n",
        "\n",
        "\"Just had the worst flight experience of my life. Delays, cancellations, and lost luggage – you name it, it happened. Absolutely disgusted with the lack of professionalism from the airline. #TravelNightmare #NeverAgain\""
      ],
      "metadata": {
        "id": "mfTkLu1K3Xud"
      }
    }
  ]
}